In PyTorch 1.8+ NaNs are no longer propagated by the min/max functions.
Hence skip those tests

See https://github.com/pytorch/pytorch/issues/57537

Author: Alexander Grund (TU Dresden)

diff --git a/test/test_binary_ufuncs.py b/test/test_binary_ufuncs.py
index 2259ae1ee5..f88277162b 100644
--- a/test/test_binary_ufuncs.py
+++ b/test/test_binary_ufuncs.py
@@ -18,6 +18,7 @@ from torch.testing._internal.common_device_type import (
     instantiate_device_type_tests, onlyCUDA, onlyCPU, dtypes, dtypesIfCUDA,
     dtypesIfCPU, deviceCountAtLeast, precisionOverride, onlyOnCPUAndCUDA,
     skipCUDAIfRocm, skipIf)
+from torch.testing._internal.common_utils import IS_PPC
 
 if TEST_SCIPY:
     import scipy.special
@@ -1154,6 +1155,7 @@ class TestBinaryUfuncs(TestCase):
             self.assertEqual(tensor_result, numpy_result)
             self.assertEqual(out, numpy_result)
 
+    @unittest.skipIf(IS_PPC, "NaNs not propagated on PPC")
     @dtypes(*(torch.testing.get_all_fp_dtypes()))
     def test_maximum_minimum_float_nan_and_inf(self, device, dtype):
         # np.maximum and np.minimum functions compare input arrays element-wisely.
@@ -1302,7 +1304,7 @@ class TestBinaryUfuncs(TestCase):
         ma = torch.max(a, b)
         mi = torch.min(a, b)
 
-        for i in range(750):
+        for i in range(500, 750):
             self.assertTrue(torch.isnan(ma[i]), "max(a, b): {}, a: {}, b: {}".format(ma[i], a[i], b[i]))
             self.assertTrue(torch.isnan(mi[i]), "min(a, b): {}, a: {}, b: {}".format(mi[i], a[i], b[i]))
 
